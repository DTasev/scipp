{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Scipp\n",
    "\n",
    "###### Multi-D data arrays with labeled dimensions\n",
    "\n",
    "`scipp` is heavily inspired by `xarray`. While for many applications `xarray` is certainly more suitable (and definitely much more matured) than `scipp`, there is a number of features missing in other situations. If your use case requires one or several of the items on the following list, using `scipp` may be worth considering:\n",
    "\n",
    "- Handling of physical units.\n",
    "- Propagation of uncertainties.\n",
    "- Support for histograms, i.e. bin-edge axes, which are by 1 longer than the data extent.\n",
    "- Support for event data, a particular form of sparse data with 1-D (or N-D) arrays of random-length lists, with very small list entries.\n",
    "- Written in C++ for better performance (for certain applications), in combination with Python bindings.\n",
    "\n",
    "This notebook demonstrates key functionality and usage of the `scipp` library. See the [documentation](https://scipp.readthedocs.io/en/latest/) for more information.\n",
    "\n",
    "## Getting started\n",
    "### What is a `Dataset`?\n",
    "The main data container in `scipp` is called a `Dataset`.\n",
    "There are two basic analogies to aid in thinking about a `Dataset`:\n",
    "1. As a `dict` of `numpy.ndarray`s, with the addition of named dimensions and units.\n",
    "2. As a table.\n",
    "\n",
    "### Creating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipp as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = sc.Dataset()\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `Dataset` as a table\n",
    "We can not only think about a dataset as a table, we can also use it as one.\n",
    "This will demonstrate the basic ways of creating datasets and interacting with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.set_coord(sc.Dim.Row, values=np.arange(3))\n",
    "d[\"alice\"] = sc.Variable([sc.Dim.Row], values=[1.0,1.1,1.2], variances=[0.01,0.01,0.02], unit=sc.units.m)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datatype (`dtype`) is derived from the provided data, so passing `np.arange(3)` will yield a variable (column) containing 64-bit integers.\n",
    "\n",
    "Datasets with up to one dimension can be displayed as a simple table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.table(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variable (column) in a dataset (table) is identified by its name (`\"alice\"`). A 1D variable will have a coordinate (`Row`), and holds `Values` and optionally `Variances` which are grouped together inside a common structure.\n",
    "\n",
    "Each variable (column) comes with a physical unit attached to it, which we should set up correctly as early as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"alice\"].unit = sc.units.m\n",
    "sc.table(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the units can also be done when constructing the `Variable` by using the `units` keyword argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"alice\"] = sc.Variable([sc.Dim.Row], values=[1.0,1.1,1.2], variances=[0.01,0.01,0.02], unit=sc.units.m)\n",
    "sc.table(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Units and uncertainties are handled automatically in operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d *= d\n",
    "sc.table(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations between columns are supported by indexing into a dataset with a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"bob\"] = d[\"alice\"]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.table(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to get a quick graphical preview on the contents of your `Dataset` by using the `show()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.show(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"bob\"] += d[\"alice\"]\n",
    "sc.table(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of  `Dataset` can also be displayed on a graph using the `plot` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.plot(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations between rows are supported by indexing into a dataset with a dimension label and an index.\n",
    "\n",
    "Slicing dimensions behaves similar to `numpy`:\n",
    "If a single index is given, the dimension is dropped, if a range is given, the dimension is kept.\n",
    "For a `Dataset`, in the former case the corresponding coordinates are dropped, whereas in the latter case it is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[4:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[sc.Dim.Row, 1] += d[sc.Dim.Row, 2]\n",
    "sc.table(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the key advantage over `numpy` or `MATLAB`:\n",
    "We specify the index dimension, so we always know which dimension we are slicing.\n",
    "The advantage is not so apparent in 1D, but will become clear once we move to higher-dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "There is a number of ways to select and operate on a single row, a range of rows, a single variable (column) or multiple variables (columns) of a dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Single row (dropping corresponding coordinates)\n",
    "sc.table(d[sc.Dim.Row, 0])\n",
    "# Size-1 row range (keeping corresponding coordinates)\n",
    "sc.table(d[sc.Dim.Row, 0:1])\n",
    "# Range of rows\n",
    "sc.table(d[sc.Dim.Row, 1:3])\n",
    "# Single variable\n",
    "sc.table(d[\"alice\"].data)\n",
    "# Subset containing a single variable, keeping coordinates\n",
    "sc.table(d[\"alice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "1. Combining row slicing and \"column\" slicing, add the last row of the data for Alice to the first row of data for Bob.\n",
    "2. Using the slice-range notation `a:b`, try adding the last two rows to the first two rows. Why does this fail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"bob\"][sc.Dim.Row, 0] += d[\"alice\"][sc.Dim.Row, -1]\n",
    "sc.table(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a range is given when slicing, the corresponding coordinate is preserved, and operations between misaligned data is prevented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    d[\"bob\"][sc.Dim.Row, 0:2] += d[\"alice\"][sc.Dim.Row, 1:3]\n",
    "except RuntimeError:\n",
    "    print(\"Failed as expected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can operate with individual variables to circumvent the safety catch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"bob\"][sc.Dim.Row, 0:2].values += d[\"alice\"][sc.Dim.Row, 1:3].values\n",
    "sc.table(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but note that the propagation of errors is then not taken into account by the operation, as we are simply adding two `numpy` arrays together.\n",
    "\n",
    "We can also imagine ways to explicitly drop coordinates from a subset, e.g., `d['bob'].drop_coords()`, to allow for direct operation with subset. This is currently not supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "The slicing notation for variables (columns) and rows does not return a copy, but a view object.\n",
    "This is very similar to how `numpy` operates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_slice = a[0:3]\n",
    "a_slice += 100\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the slicing notation, create a new table (or replace the existing dataset `d`) by one that does not contain the first and last row of `d`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d[sc.Dim.Row, 1:-1].copy()\n",
    "\n",
    "# Or:\n",
    "# from copy import copy\n",
    "# table = copy(d[Dim.Row, 1:-1])\n",
    "\n",
    "sc.table(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More advanced operations with tables\n",
    "In addition to binary operators, basic functions like `concatenate`, `sort`, and `merge` are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = sc.concatenate(d[sc.Dim.Row, 0:3], d[sc.Dim.Row, 1:3], sc.Dim.Row)\n",
    "d = sc.sort(d, sc.Dim.Row)\n",
    "eve = sc.Dataset()\n",
    "eve[\"eve\"] = sc.Variable([sc.Dim.Row], values=np.arange(5).astype(np.float64))\n",
    "d.merge(eve)\n",
    "sc.table(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "Add the sum of the data for `alice` and `bob` as a new variable (column) to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['sum'] = d['alice'] + d['bob']\n",
    "sc.table(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction with `numpy` and scalars\n",
    "Variable in a dataset are exposed in a `numpy`-compatible buffer format, so we can directly hand them to `numpy` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['eve'] = np.exp(d['eve'])\n",
    "sc.table(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Direct access to the `numpy`-like underlying data array is possible using the `values` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['eve'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "1. As above for `np.exp` applied to the data for Eve, apply a `numpy` function to the data for Alice.\n",
    "2. What happens to the unit and uncertanties when modifying data with external code such as `numpy`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['alice'] = np.sin(d['alice'])\n",
    "sc.table(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy operations are not aware of the unit and uncertainties. Therefore the result is garbage, unless the user has ensured herself that units and uncertainties are handled manually.\n",
    "\n",
    "Corollary: Whenever available, built-in operators and functions should be preferred over the use of `numpy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "1. Try adding a scalar value such as `1.5` to the data for Eve.\n",
    "2. Try the same for Alice or Bob. Why is it not working?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['eve'] += 1.5\n",
    "sc.table(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for Alice has a unit, so a direct addition with a dimensionless quantity fails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    d['alice'] += 1.5\n",
    "except RuntimeError:\n",
    "    print(\"Failed as expected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `Variable` to provide scalar quantity with attached unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['alice'] += sc.Variable(1.5, unit=sc.units.m*sc.units.m)\n",
    "sc.table(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue to [Dataset in a Nutshell - Part 2](demo-part2.ipynb) to see how datasets are used with multi-dimensional data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
