{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-dimensional datasets\n",
    "\n",
    "This is the continuation of [Introduction to Scipp](introduction.ipynb).\n",
    "\n",
    "## Creation, slicing, and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipp as sc\n",
    "from scipp import Dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create variables with more than one dimension we specify a list of dimension labels and provide data with a corresponding shape. When inserted into a dataset it is important to note that while the dimensions extents have to match, individual variables may have transposed memory layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = sc.Dataset()\n",
    "d.set_coord(Dim.X, sc.Variable([sc.Dim.X], values=np.arange(11.0), unit=sc.units.m))\n",
    "d.set_coord(Dim.Y, sc.Variable([sc.Dim.Y], values=np.arange(11.0), unit=sc.units.m))\n",
    "d.set_coord(Dim.Z, sc.Variable([sc.Dim.Z], values=np.arange(11.0), unit=sc.units.m))\n",
    "d[\"alice\"] = sc.Variable([Dim.Z, Dim.Y, Dim.X], values=np.random.rand(10, 10, 10), variances=0.1*np.random.rand(10, 10, 10))\n",
    "d[\"bob\"] = sc.Variable([Dim.X, Dim.Z], values=np.arange(0.0, 10.0, 0.1).reshape(10, 10), variances=0.1*np.random.rand(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this example the coordinates are exceeding the shape of the data by 1.\n",
    " This means that the coordinates represent bin edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To slice in multiple dimensions, we can simply chain the slicing notation used previously for 1D data.\n",
    " This gives us a number of different options for visualizing our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.table(d[Dim.X, 5][Dim.Z, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are able to plot individual elements of a `Dataset` by doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.plot(d[\"bob\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also plot the standard deviations alongside the values with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.plot(d[\"bob\"], show_variances=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting a 3-dimensional data cube will show a 2D image with a slider to navigate through the third dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.plot(d[\"alice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, by extracting a 1D variable, we obtain a 1D plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.plot(d[Dim.X, 8][Dim.Y, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is now plotted as a histogram since the coordinate in the dataset is bin edges, in contrast to the 1D data plotted in part 1.\n",
    "\n",
    "Operations automatically broadcast based on dimension labels. In contrast to `numpy` or `MATLAB` there is no need to keep track of dimension order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"alice\"] -= d[\"bob\"]\n",
    "d[\"alice\"] -= d[\"alice\"][Dim.Y, 5]\n",
    "sc.plot(d[\"alice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    " Remove the surface layer of the volume, i.e., remove the first and last slice in each of the dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d[Dim.X, 1:-1][Dim.Y, 1:-1][Dim.Z, 1:-1].copy()\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the important call to `copy()`.\n",
    "If we omit it, `d` will just be a multi-dimensional slice of the larger volume (which is kept alive), wasting memory and preventing further modification, such as insertion of other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More advanced operations with multi-dimensional datasets\n",
    "Operations like `concatenate` and `sort` work just like with one-dimensional datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "- Try to concatenate the dataset with itself along the X dimensions. Why does this fail?\n",
    "- Make a copy of the dataset, add an offset to the X coordinate to fix the issue, and try to concatenate again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    d = sc.concatenate(d, d, Dim.X)\n",
    "except RuntimeError:\n",
    "    print(\"Failed as expected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a data extent of, e.g. `8` in this case, bin edges have extent `9`.\n",
    "Naive concatenation would thus lead a new data extent of `16` and a coordinate extent of `18`, which is meaningless and thus prevented.\n",
    "In this `concatenate` merges the last edge of the first input with the first edge of the second input, if compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = d.copy()\n",
    "offset.coords[Dim.X] += sc.Variable(8.0, unit=sc.units.m)\n",
    "combined = sc.concatenate(d, offset, Dim.X)\n",
    "sc.plot(combined['alice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another available operation is `rebin`.\n",
    " This is only for count-data or count-density-data, so we have to set an appropriate unit first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = sc.Variable([Dim.X], values=d.coords[Dim.X].values[::2])\n",
    "d['alice'].unit = sc.units.counts\n",
    "d['bob'].unit = sc.units.counts\n",
    "d = sc.rebin(d, new_x)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction with `numpy`\n",
    " Variable in a dataset are exposed in a `numpy`-compatible buffer format, so we can directly hand them to `numpy` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['alice'] = np.sin(d['alice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Direct access to the `numpy`-like underlying data array is possible using the `values` property. This is now a multi-dimensional array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['alice'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    " 1. Use `ds.mean` to compute the mean of the data for Alice along the Z dimension.\n",
    " 2. Do the same with `numpy`, what are the complications you encounter, that are not present when using the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sc.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = sc.mean(d['alice'], Dim.Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using `numpy` to compute the mean:\n",
    "- We must remember (or lookup) which dimension corresponds to the Z dimensions.\n",
    "- We need a separate call for values and variances.\n",
    "- We need to manually scale the variance with the inverse square of the number of data points to get the variance of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_value = np.mean(d['alice'].values, axis=0)\n",
    "np_variance = np.mean(d['alice'].variances, axis=0)\n",
    "np_variance /= np.sqrt(d.dimensions[Dim.Z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue to [Part 3 - Neutron data](neutron-data.ipynb) to see how datasets are used with neutron-event data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbsphinx": {
   "allow_errors": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
